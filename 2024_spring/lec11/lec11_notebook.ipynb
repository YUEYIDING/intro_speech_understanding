{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a424b44",
   "metadata": {},
   "source": [
    "# Speech Understanding \n",
    "# Lecture 11: The SpeechRecognition Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3983e7c",
   "metadata": {},
   "source": [
    "### Mark Hasegawa-Johnson, KCGI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa13a99",
   "metadata": {},
   "source": [
    "In today's lecture, we will learn how to use the <a href=\"https://pypi.org/project/SpeechRecognition/\">Speech Recognition</a> module in order to access high-performance commercial and open-source speech recognizers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8ca0a6",
   "metadata": {},
   "source": [
    "Here are the contents:\n",
    "1. <a href=\"#section1\">Installing SpeechRecognition</a>\n",
    "1. <a href=\"#section2\">Using SpeechRecognition</a>\n",
    "1. <a href=\"#section3\">Installing PyAudio</a>\n",
    "1. <a href=\"#section4\">Handling microphone issues using exception processing</a>\n",
    "1. <a href=\"#homework\">Homework</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f5b87c",
   "metadata": {},
   "source": [
    "<a id='section1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc1f1a1",
   "metadata": {},
   "source": [
    "## 1. Installing SpeechRecognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c958c9dc",
   "metadata": {},
   "source": [
    "The `SpeechRecognition` module can be used to call a wide variety of speech-to-text systems.  By default, it uses the Google speech recognizer, which requires web access, but you can set it to use a local speech recognizer on your own machine.  It is installed using pip:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0c7fd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in /opt/anaconda3/lib/python3.11/site-packages (3.10.4)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/anaconda3/lib/python3.11/site-packages (from SpeechRecognition) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.11/site-packages (from SpeechRecognition) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->SpeechRecognition) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->SpeechRecognition) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->SpeechRecognition) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731a115a",
   "metadata": {},
   "source": [
    "<a id='section2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f8148f",
   "metadata": {},
   "source": [
    "## 2. Using SpeechRecognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35200b1",
   "metadata": {},
   "source": [
    "In order to use the `SpeechRecognition` module, we need to create two types of objects.\n",
    "\n",
    "1. A `Recognizer` object contains the information necessary to do speech recognition.  For example, this object knows whether you're using Google or some other speech recognizer (by default, Google).\n",
    "1. You also need some type of audio source.  There are two main types of audio source:\n",
    "    1. A `Microphone` object gets audio from your computer's microphone\n",
    "    1. An `AudioFile` object gets audio from an audio file\n",
    "\n",
    "Once you have created both types of objects, then you need to do three things:\n",
    "1. Get audio from the audio source into the speech recognizer, and\n",
    "1. Convert the audio into text,\n",
    "1. Print out what the person said\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f7748c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The person in this audio file said: thank you please wait for assistance .\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition\n",
    "\n",
    "r = speech_recognition.Recognizer()\n",
    "\n",
    "with speech_recognition.AudioFile(\"264752__copyc4t__phone-messages-english-and-italian.flac\") as source:\n",
    "    audio = r.record(source)\n",
    "    text = r.recognize_google(audio)\n",
    "    print('The person in this audio file said:',text,'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500c2dc3",
   "metadata": {},
   "source": [
    "And... it worked!  Except, did the speaker in this audio file really repeat the word \"assistance\" twice?   Let's find out, by loading the audio file, looking at it, and listening to it.\n",
    "\n",
    "This particular audio file was downloaded from https://freesound.org/people/copyc4t/sounds/264752/, and it is available under a CC-BY 4.0 license, so if you use it, you should say that you got it from copyc4t at freesound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac3ead74",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlibrosa\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m y, sr \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m264752__copyc4t__phone-messages-english-and-italian.flac\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "y, sr = librosa.load('264752__copyc4t__phone-messages-english-and-italian.flac')\n",
    "print('Length is',len(y),', rate is ',sr,', duration is',len(y)/sr)\n",
    "time_axis = np.arange(len(y))/sr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(14,2))\n",
    "subplot = fig.subplots(1,1)\n",
    "subplot.plot(time_axis, y)\n",
    "subplot.set_xlabel('Time (seconds)',fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "608b8ceb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m IPython\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mAudio(data\u001b[38;5;241m=\u001b[39my,rate\u001b[38;5;241m=\u001b[39msr)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "IPython.display.Audio(data=y,rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02605dad",
   "metadata": {},
   "source": [
    "As you can see, this file has two parts:\n",
    "\n",
    "* The first four seconds are in English\n",
    "* The rest is in Italian\n",
    "\n",
    "So we should probably tell the `Recognizer` to recognize the first part in English, and the last part in Italian.  We can do that using the following keyword arguments:\n",
    "\n",
    "* The `record` method takes `offset` and `duration` arguments, in seconds.  See https://realpython.com/python-speech-recognition/ \n",
    "* The `recognize_google` method takes `language` as an argument.  The language codes you can use are listed here: https://cloud.google.com/speech-to-text/docs/speech-to-text-supported-languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eea4683c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The English part of this audio file says: thank you please wait for assistance .\n",
      "\n",
      "The Italian part of this audio file says: grazie lo preghiamo di attendere per ricevere assistenza .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with speech_recognition.AudioFile(\"264752__copyc4t__phone-messages-english-and-italian.flac\") as source:\n",
    "    \n",
    "    # First, recognize the English part\n",
    "    audio = r.record(source,duration=4)\n",
    "    text = r.recognize_google(audio,language='en')\n",
    "    print('The English part of this audio file says:',text,'.\\n')\n",
    "    \n",
    "    # Second, recognize the Italian part\n",
    "    audio = r.record(source)\n",
    "    text = r.recognize_google(audio,language='it')\n",
    "    print('The Italian part of this audio file says:',text,'.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900bc6fd",
   "metadata": {},
   "source": [
    "<a id='section3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d30896",
   "metadata": {},
   "source": [
    "## 3. Installing PyAudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b754c221",
   "metadata": {},
   "source": [
    "Recognizing from the microphone just requires us to use a `Microphone` object as the source, instead of an `AudioFile` object.  But there are some special problems to pay attention to.\n",
    "\n",
    "First, in order for `speech_recognizer` to listen to your microphone, you need to have PyAudio installed.  The following code should install PyAudio for you.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ba07703a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - pyaudio\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - defaults\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install PyAudio -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fda43d",
   "metadata": {},
   "source": [
    "Now try the following, to see if it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a17ce0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Could not find PyAudio; check installation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/speech_recognition/__init__.py:108\u001b[0m, in \u001b[0;36mMicrophone.get_pyaudio\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyaudio\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyaudio'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspeech_recognition\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m mic \u001b[38;5;241m=\u001b[39m speech_recognition\u001b[38;5;241m.\u001b[39mMicrophone()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/speech_recognition/__init__.py:80\u001b[0m, in \u001b[0;36mMicrophone.__init__\u001b[0;34m(self, device_index, sample_rate, chunk_size)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunk_size, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m chunk_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChunk size must be a positive integer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# set up PyAudio\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpyaudio_module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_pyaudio()\n\u001b[1;32m     81\u001b[0m audio \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpyaudio_module\u001b[38;5;241m.\u001b[39mPyAudio()\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/speech_recognition/__init__.py:110\u001b[0m, in \u001b[0;36mMicrophone.get_pyaudio\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyaudio\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find PyAudio; check installation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LooseVersion\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LooseVersion(pyaudio\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m LooseVersion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.2.11\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mAttributeError\u001b[0m: Could not find PyAudio; check installation"
     ]
    }
   ],
   "source": [
    "import speech_recognition\n",
    "mic = speech_recognition.Microphone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a64059",
   "metadata": {},
   "source": [
    "If that worked, then all is well. If that failed, then it might mean you need to re-start your kernel.  Try the following:\n",
    "\n",
    "* Go to the **Kernel** menu at the top of this page\n",
    "* Choose **Change kernel**\n",
    "* Choose any one of the listed kernels.  For example, you could choose **Python3 (ipykernel)** or you could choose **Python [conda env:root]**\n",
    "\n",
    "This will re-start your kernel, and re-load everything.  Hopefully, now PyAudio and `speech_recognition.Microphone()` will work.\n",
    "\n",
    "If they don't work, (1) you won't be able to do speech recognition from your microphone, but (2) you can still do the homework, because the homework only uses audio files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd37be9",
   "metadata": {},
   "source": [
    "<a id='section4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8857e202",
   "metadata": {},
   "source": [
    "## 4. Handling microphone issues using exception processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a5eb6d",
   "metadata": {},
   "source": [
    "Before we start recognizing, we should adjust for background noise.  This is done using the command `r.adjust_for_ambient_noise(source)`.\n",
    "\n",
    "Second, what happens if the speech recognizer listens for a while, and then doesn't understand what it hears?  If this happens, either the `listen` function or the `recognize_google` function will raise an exception.\n",
    "\n",
    "Python's exception handling is exceptional.  I strongly recommend that you learn about it, by studying this tutorial: https://docs.python.org/3/tutorial/errors.html.  But in case you don't have time, here are the basics:\n",
    "\n",
    "* Any function can raise an exception using the syntax `raise ...`, where `...` is some subclass of the `exception` class.  For example, a typical exception is `raise RuntimeError`.\n",
    "* If that function was not inside a `try` envelope, then the code stops running at that point, and prints an error.\n",
    "* It that function was inside a `try` envelope, then python checks after the `try` to see if there is an `except` clause.  If there is, then instead of just stopping execution, python runs the code in the `except` clause.\n",
    "\n",
    "This syntax allows us to basically ignore more speech recognition errors.  Our strategy will be to put the `r.listen` and `r.recognize_google` functions inside a `try` clause, inside a `while True` loop.\n",
    "\n",
    "* If there is a `speech_recognizer.WaitTimeoutError`, it means that the `listen` command listened for too long but didn't hear anything.  In that case, we use `continue` to go back to the beginning of the loop and try again.\n",
    "* If there is a `speech_recognizer.RequestError`, it means that the `recognize_google` command couldn't reach google over the internet.  In that case, we use `continue` to go back to the beginning of the loop and try again.\n",
    "* If there is a `speech_recognizer.UnknownValueError`, it means that the `recognize_google` command couldn't understand what you said.  In that case, use use `continue` to go back to the beginning of the loop and try again.\n",
    "* If none of the above is true, then we assume the text is correct, so we use a `break` command to break out of the loop and print the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "832e9140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is listening...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Could not find PyAudio; check installation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/speech_recognition/__init__.py:108\u001b[0m, in \u001b[0;36mMicrophone.get_pyaudio\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyaudio\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyaudio'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPython is listening...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m speech_recognition\u001b[38;5;241m.\u001b[39mMicrophone() \u001b[38;5;28;01mas\u001b[39;00m source:\n\u001b[1;32m      7\u001b[0m         r\u001b[38;5;241m.\u001b[39madjust_for_ambient_noise(source)\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/speech_recognition/__init__.py:80\u001b[0m, in \u001b[0;36mMicrophone.__init__\u001b[0;34m(self, device_index, sample_rate, chunk_size)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunk_size, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m chunk_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChunk size must be a positive integer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# set up PyAudio\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpyaudio_module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_pyaudio()\n\u001b[1;32m     81\u001b[0m audio \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpyaudio_module\u001b[38;5;241m.\u001b[39mPyAudio()\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/speech_recognition/__init__.py:110\u001b[0m, in \u001b[0;36mMicrophone.get_pyaudio\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyaudio\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find PyAudio; check installation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LooseVersion\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LooseVersion(pyaudio\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m LooseVersion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.2.11\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mAttributeError\u001b[0m: Could not find PyAudio; check installation"
     ]
    }
   ],
   "source": [
    "import speech_recognition\n",
    "r = speech_recognition.Recognizer()\n",
    "\n",
    "while True:\n",
    "    print('Python is listening...')\n",
    "    with speech_recognition.Microphone() as source:\n",
    "        r.adjust_for_ambient_noise(source)\n",
    "        try:\n",
    "            audio = r.listen(source)\n",
    "            text = r.recognize_google(audio, language='en')\n",
    "        except speech_recognition.UnknownValueError:\n",
    "            print('I did not understand that, I will try again')\n",
    "            continue\n",
    "        except sr.RequestError:\n",
    "            print('Sorry, I could not reach the internet, I will try again')\n",
    "            continue\n",
    "        except sr.WaitTimeoutError:\n",
    "            continue\n",
    "        break\n",
    "\n",
    "print('You said:',text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564707ab",
   "metadata": {},
   "source": [
    "<a id='homework'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6b32d4",
   "metadata": {},
   "source": [
    "## Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9eeaa5",
   "metadata": {},
   "source": [
    "Open the file called `homework11.py`.\n",
    "\n",
    "This file should `def` a function called `transcribe_wavefile`, with the following signature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8c8138f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (homework11.py, line 24)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3553\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[51], line 2\u001b[0m\n    importlib.reload(homework11)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m/opt/anaconda3/lib/python3.11/importlib/__init__.py:169\u001b[0m in \u001b[1;35mreload\u001b[0m\n    _bootstrap._exec(spec, module)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap>:621\u001b[0m in \u001b[1;35m_exec\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap_external>:936\u001b[0m in \u001b[1;35mexec_module\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap_external>:1074\u001b[0m in \u001b[1;35mget_code\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap_external>:1004\u001b[0m in \u001b[1;35msource_to_code\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0;36m in \u001b[0;35m_call_with_frames_removed\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/Downloads/intro_speech_understanding/2024_spring/lec11/homework11.py:24\u001b[0;36m\u001b[0m\n\u001b[0;31m    return text\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import homework11, importlib\n",
    "importlib.reload(homework11)\n",
    "help(homework11.transcribe_wavefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9fb7cc",
   "metadata": {},
   "source": [
    "Test whether your code works by running the following block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0ab6ecae",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (homework11.py, line 23)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3553\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[49], line 2\u001b[0m\n    importlib.reload(homework11)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m/opt/anaconda3/lib/python3.11/importlib/__init__.py:169\u001b[0m in \u001b[1;35mreload\u001b[0m\n    _bootstrap._exec(spec, module)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap>:621\u001b[0m in \u001b[1;35m_exec\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap_external>:936\u001b[0m in \u001b[1;35mexec_module\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap_external>:1074\u001b[0m in \u001b[1;35mget_code\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap_external>:1004\u001b[0m in \u001b[1;35msource_to_code\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0;36m in \u001b[0;35m_call_with_frames_removed\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/Downloads/intro_speech_understanding/2024_spring/lec11/homework11.py:23\u001b[0;36m\u001b[0m\n\u001b[0;31m    return text\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import importlib,homework11\n",
    "importlib.reload(homework11)\n",
    "\n",
    "text = homework11.transcribe_wavefile(\"264752__copyc4t__phone-messages-english-and-italian.flac\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35625b2",
   "metadata": {},
   "source": [
    "### Receiving your grade\n",
    "\n",
    "In order to receive a grade for your homework, you need to:\n",
    "\n",
    "1. Run the following code block on your machine.  The result may list some errors, and then in the very last line, it will show a score.  That score (between 0% and 100%) is the grade you have earned so far.  If you want to earn a higher grade, please continue editing `homework3.py`, and then run this code block again.\n",
    "1. When you are happy with your score (e.g., when it reaches 100%), choose `File` $\\Rightarrow$ `Save and Checkpoint`.  Then use `GitHub Desktop` to commit and push your changes.\n",
    "1. Make sure that the 100% shows on your github repo on github.com.  If it doesn't, you will not receive credit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "38daa6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EFE\n",
      "======================================================================\n",
      "ERROR: test_method_returns_str (grade.Test.test_method_returns_str)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yueyiding/Downloads/intro_speech_understanding/2024_spring/lec11/grade.py\", line 25, in test_method_returns_str\n",
      "    transcription = homework11.transcribe_wavefile(\"webdata.wav\")\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yueyiding/Downloads/intro_speech_understanding/2024_spring/lec11/homework11.py\", line 16, in transcribe_wavefile\n",
      "    #raise RuntimeError(\"FAIL!!  You need to change this function so it works!\")\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: FAIL!!  You need to change this function so it works!\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_method_works_with_known_input (grade.Test.test_method_works_with_known_input)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yueyiding/Downloads/intro_speech_understanding/2024_spring/lec11/grade.py\", line 35, in test_method_works_with_known_input\n",
      "    transcription = homework11.transcribe_wavefile(filename)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yueyiding/Downloads/intro_speech_understanding/2024_spring/lec11/homework11.py\", line 16, in transcribe_wavefile\n",
      "    #raise RuntimeError(\"FAIL!!  You need to change this function so it works!\")\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: FAIL!!  You need to change this function so it works!\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_method_runs (grade.Test.test_method_runs)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yueyiding/Downloads/intro_speech_understanding/2024_spring/lec11/grade.py\", line 18, in test_method_runs\n",
      "    transcription = homework11.transcribe_wavefile(\"webdata.wav\")\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yueyiding/Downloads/intro_speech_understanding/2024_spring/lec11/homework11.py\", line 16, in transcribe_wavefile\n",
      "    #raise RuntimeError(\"FAIL!!  You need to change this function so it works!\")\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: FAIL!!  You need to change this function so it works!\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yueyiding/Downloads/intro_speech_understanding/2024_spring/lec11/grade.py\", line 20, in test_method_runs\n",
      "    self.fail(\"homework11.transcribe_wavefile does not run (has errors)\")\n",
      "AssertionError: homework11.transcribe_wavefile does not run (has errors)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.011s\n",
      "\n",
      "FAILED (failures=1, errors=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 successes out of 3 tests run\n",
      "Score: 0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'grade' from '/Users/yueyiding/Downloads/intro_speech_understanding/2024_spring/lec11/grade.py'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib, grade\n",
    "importlib.reload(grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b59948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
